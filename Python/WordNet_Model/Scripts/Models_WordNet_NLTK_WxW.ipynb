{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import nltk\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import WordNet dataset\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "objectStrings = []\n",
    "objectSets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of Target Objects\n",
    "objects = ['baby', 'book', 'bottle', 'cat', 'dog', 'hand', 'shoe', 'spoon']\n",
    "\n",
    "# WordNet Senses Corresponding to the target objects (hand coded by Ananya Mittal)\n",
    "objectStrings = ['baby.n.01', 'book.n.01', 'bottle.n.01', 'cat.n.01', \n",
    "                 'dog.n.01',  'hand.n.01', 'shoe.n.01',   'spoon.n.01']\n",
    "\n",
    "# Get synsets for target objects\n",
    "for o in objectStrings:\n",
    "    objectSets.append(wn.synset(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of all MCDI words, including hand coded senses for each word\n",
    "mcdi_df = pd.read_csv('MCDI.csv')\n",
    "mcdi_df.columns = ['words','entry','pos','sense','string']\n",
    "data = mcdi_df[['words','string']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DF\n",
    "mcdi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get synsets for each word\n",
    "def find_synset(st):\n",
    "    try:\n",
    "        return wn.synset(st)\n",
    "    except:\n",
    "        return None\n",
    "mcdi_df['synset'] = mcdi_df['string'].map(lambda x: find_synset(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DF\n",
    "mcdi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DFs to store similarity ratings (MCDI x MCDI)\n",
    "similarity_df_PL = pd.DataFrame(0.0, index=range(len(mcdi_df['words'])), columns=range(len(mcdi_df['words'])))\n",
    "similarity_df_LCH = pd.DataFrame(0.0, index=range(len(mcdi_df['words'])), columns=range(len(mcdi_df['words'])))\n",
    "similarity_df_WUP = pd.DataFrame(0.0, index=range(len(mcdi_df['words'])), columns=range(len(mcdi_df['words'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: check if a given word has synsets\n",
    "def has_synset(st):\n",
    "    if st is None: return False\n",
    "    else: return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word in the MCDI, check that they all have synsets\n",
    "i = 0\n",
    "j = 0\n",
    "index_ct = 0\n",
    "\n",
    "for st in mcdi_df['synset']:\n",
    "    if has_synset(st) == False: \n",
    "        i = i+1\n",
    "        print(index_ct)\n",
    "        \n",
    "    else: j = j+1\n",
    "        \n",
    "    index_ct = index_ct+1\n",
    "    \n",
    "print(\"Number of words that do not have any synsets: \", i)\n",
    "print(\"Number of words that do have synsets        : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Path length similarity between BABY and babysitter\n",
    "if(has_synset(mcdi_df['synset'][6])==True):\n",
    "    similarity_df_PL[0][6] = objectSets[0].path_similarity(mcdi_df['synset'][6])\n",
    "print(\"similarity = \", round(similarity_df_PL[0][6],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate similarity DFs using different measures of similarity\n",
    "for w in range(len(mcdi_df['words'])): \n",
    "    for w2 in range(len(mcdi_df['words'])): \n",
    "        if(has_synset(mcdi_df['synset'][w])==True):\n",
    "            similarity_df_PL[w2][w] = mcdi_df['synset'][w2].path_similarity(mcdi_df['synset'][w])\n",
    "            similarity_df_LCH[w2][w] = mcdi_df['synset'][w2].lch_similarity(mcdi_df['synset'][w])\n",
    "            similarity_df_WUP[w2][w] = mcdi_df['synset'][w2].wup_similarity(mcdi_df['synset'][w])\n",
    "        else:\n",
    "            similarity_df_PL[w2][w] = None\n",
    "            similarity_df_LCH[w2][w] = None\n",
    "            similarity_df_WUP[w2][w] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df_PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format DFs\n",
    "similarity_df_PL.columns = mcdi_df['words']\n",
    "similarity_df_LCH.columns = mcdi_df['words']\n",
    "similarity_df_WUP.columns = mcdi_df['words']\n",
    "\n",
    "similarity_df_PL['words'] = mcdi_df['words']\n",
    "similarity_df_LCH['words'] = mcdi_df['words']\n",
    "similarity_df_WUP['words'] = mcdi_df['words']\n",
    "\n",
    "similarity_df_PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Words x Words Models to CSVs\n",
    "similarity_df_PL.to_csv('path_similarity_WxW.csv')\n",
    "similarity_df_LCH.to_csv('lch_similarity_WxW.csv')\n",
    "similarity_df_WUP.to_csv('wup_similarity_WxW.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
