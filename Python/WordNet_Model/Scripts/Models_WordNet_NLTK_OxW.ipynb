{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import nltk\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import WordNet dataset\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "objectStrings = []\n",
    "objectSets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of Target Objects\n",
    "objects = ['baby', 'book', 'bottle', 'cat', 'dog', 'hand', 'shoe', 'spoon']\n",
    "\n",
    "# WordNet Senses Corresponding to the target objects (hand coded by Ananya Mittal)\n",
    "objectStrings = ['baby.n.01', 'book.n.01', 'bottle.n.01', 'cat.n.01', \n",
    "                 'dog.n.01',  'hand.n.01', 'shoe.n.01',   'spoon.n.01']\n",
    "\n",
    "# Get synsets for target objects\n",
    "for o in objectStrings:\n",
    "    objectSets.append(wn.synset(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of all MCDI words, including hand coded senses for each word\n",
    "mcdi_df = pd.read_csv('MCDI.csv')\n",
    "mcdi_df.columns = ['words','entry','pos','sense','string']\n",
    "data = mcdi_df[['words','string']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DF\n",
    "mcdi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get synsets for each word\n",
    "def find_synset(st):\n",
    "    try:\n",
    "        return wn.synset(st)\n",
    "    except:\n",
    "        return None\n",
    "mcdi_df['synset'] = mcdi_df['string'].map(lambda x: find_synset(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DF\n",
    "mcdi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DFs to store similarity ratings (OBJECTS x MCDI)\n",
    "similarity_df_PL = pd.DataFrame(0.0, index=range(len(mcdi_df['words'])), columns=range(len(objects)))\n",
    "similarity_df_LCH = pd.DataFrame(0.0, index=range(len(mcdi_df['words'])), columns=range(len(objects)))\n",
    "similarity_df_WUP = pd.DataFrame(0.0, index=range(len(mcdi_df['words'])), columns=range(len(objects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: check if a given word has synsets\n",
    "def has_synset(st):\n",
    "    if st is None: return False\n",
    "    else: return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word in the MCDI, check that they all have synsets\n",
    "i = 0\n",
    "j = 0\n",
    "index_ct = 0\n",
    "\n",
    "for st in mcdi_df['synset']:\n",
    "    if has_synset(st) == False: \n",
    "        i = i+1\n",
    "        print(index_ct)\n",
    "        \n",
    "    else: j = j+1\n",
    "        \n",
    "    index_ct = index_ct+1\n",
    "    \n",
    "print(\"Number of words that do not have any synsets: \", i)\n",
    "print(\"Number of words that do have synsets        : \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Path length similarity between BABY and babysitter\n",
    "if(has_synset(mcdi_df['synset'][6])==True):\n",
    "    similarity_df_PL[0][6] = objectSets[0].path_similarity(mcdi_df['synset'][6])\n",
    "print(\"similarity = \", round(similarity_df_PL[0][6],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate similarity DFs using different measures of similarity\n",
    "for w in range(len(mcdi_df['words'])): \n",
    "    for o in range(len(objects)): \n",
    "        if(has_synset(mcdi_df['synset'][w])==True):\n",
    "            similarity_df_PL[o][w] = objectSets[o].path_similarity(mcdi_df['synset'][w])\n",
    "            similarity_df_LCH[o][w] = objectSets[o].lch_similarity(mcdi_df['synset'][w])\n",
    "            similarity_df_WUP[o][w] = objectSets[o].wup_similarity(mcdi_df['synset'][w])\n",
    "        else:\n",
    "            similarity_df_PL[o][w] = None\n",
    "            similarity_df_LCH[o][w] = None\n",
    "            similarity_df_WUP[o][w] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df_PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format DFs\n",
    "similarity_df_PL.columns = ['BABY', 'BOOK', 'BOTTLE', 'CAT', 'DOG', 'HAND', 'SHOE', 'SPOON']\n",
    "similarity_df_LCH.columns = ['BABY', 'BOOK', 'BOTTLE', 'CAT', 'DOG', 'HAND', 'SHOE', 'SPOON']\n",
    "similarity_df_WUP.columns = ['BABY', 'BOOK', 'BOTTLE', 'CAT', 'DOG', 'HAND', 'SHOE', 'SPOON']\n",
    "\n",
    "similarity_df_PL.rename(index = mcdi_df['words'])\n",
    "similarity_df_LCH.rename(index = mcdi_df['words'])\n",
    "similarity_df_WUP.rename(index = mcdi_df['words'])\n",
    "\n",
    "similarity_df_PL['words'] = mcdi_df['words']\n",
    "similarity_df_LCH['words'] = mcdi_df['words']\n",
    "similarity_df_WUP['words'] = mcdi_df['words']\n",
    "\n",
    "similarity_df_WUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check: Test BABY\n",
    "simA_ind_BABY = similarity_df_PL.sort_values(by=['BABY'], axis = 0, ascending = False)[0:12]['BABY']\n",
    "simB_ind_BABY = similarity_df_LCH.sort_values(by=['BABY'], axis = 0, ascending = False)[0:12]['BABY']\n",
    "simC_ind_BABY = similarity_df_WUP.sort_values(by=['BABY'], axis = 0, ascending = False)[0:12]['BABY']\n",
    "\n",
    "print(simA_ind_BABY)\n",
    "print(simB_ind_BABY)\n",
    "print(simC_ind_BABY)\n",
    "\n",
    "# 62  = child\n",
    "# 182 = person\n",
    "# 263 = plant\n",
    "# 4   = aunt\n",
    "# 188 = animal\n",
    "# 1   = dog\n",
    "# 35  = man\n",
    "# 39  = boy\n",
    "# 110 = sister\n",
    "# 61  = child\n",
    "# 142 = brother\n",
    "# 81  = bird\n",
    "# 195 = lady\n",
    "# 109 = lady\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check: Test BOOK\n",
    "simA_ind_BOOK = similarity_df_PL.sort_values(by=['BOOK'], axis = 0, ascending = False)[1:12]['BOOK']\n",
    "simB_ind_BOOK = similarity_df_LCH.sort_values(by=['BOOK'], axis = 0, ascending = False)[1:12]['BOOK']\n",
    "simC_ind_BOOK = similarity_df_WUP.sort_values(by=['BOOK'], axis = 0, ascending = False)[1:12]['BOOK']\n",
    "\n",
    "print(simA_ind_BOOK)\n",
    "print(simB_ind_BOOK)\n",
    "print(simC_ind_BOOK)\n",
    "\n",
    "# 215 = toy\n",
    "# 161 = picture\n",
    "# 25  = block\n",
    "# 75  = doll\n",
    "# 45  = cake\n",
    "# 169 = pool\n",
    "# 234 = zoo\n",
    "# 78  = drawer\n",
    "# 170 = potty\n",
    "# 73  = dish\n",
    "# 196 = stairs\n",
    "# 30  = box\n",
    "# 183 = shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Object x Words Models to CSVs\n",
    "similarity_df_PL.to_csv('path_similarity_OxW.csv')\n",
    "similarity_df_LCH.to_csv('lch_similarity_OxW.csv')\n",
    "similarity_df_WUP.to_csv('wup_similarity_OxW.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
